{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_nlp"
      ],
      "metadata": {
        "id": "blHxVcq3UqCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqQXpHLfQBlF",
        "outputId": "f624d246-746f-4ca3-fba6-909fb9976ed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gpt2-ft-pipeline'...\n",
            "remote: Enumerating objects: 23, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 23 (delta 4), reused 12 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (23/23), 16.57 KiB | 2.07 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/deep-diver/gpt2-ft-pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ogUTvPjVQQj1"
      },
      "outputs": [],
      "source": [
        "!mv gpt2-ft-pipeline/alpaca ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0g1FPqQRRUF",
        "outputId": "8989e944-3a99-4826-faab-b635f91f9124"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/alpaca\n",
            "INFO[build.py]: Loading dataset  from path: /content/alpaca/alpaca_dataset_builder.py\n",
            "2023-06-18 11:51:34.506695: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-18 11:51:35.500851: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-06-18 11:51:35.833366: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-06-18 11:51:36.332646: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-06-18 11:51:36.333012: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-06-18 11:51:38.342715: W tensorflow/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"NOT_FOUND: Error executing an HTTP request: HTTP response code 404\".\n",
            "INFO[build.py]: download_and_prepare for dataset alpaca/1.0.0...\n",
            "INFO[dataset_builder.py]: Generating dataset alpaca (/root/tensorflow_datasets/alpaca/1.0.0)\n",
            "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /root/tensorflow_datasets/alpaca/1.0.0...\u001b[0m\n",
            "Dl Completed...: 0 url [00:00, ? url/s]\n",
            "                                       \n",
            "\u001b[AINFO[download_manager.py]: Downloading https://github.com/tloen/alpaca-lora/raw/main/alpaca_data.json into /root/tensorflow_datasets/downloads/tloen_alpaca-lora_raw_main_alpaca_data4Au3mCuTvwNKcdqSKmlcWQaDUk2-e5GtRsgF8LMbqRE.json.tmp.44bfaa54e7524259b67f53fa087ef7fb...\n",
            "Dl Completed...: 0 url [00:00, ? url/s]\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Completed...:   0% 0/1 [00:04<?, ? url/s]\n",
            "Dl Size...:   0% 0/6 [00:04<?, ? MiB/s]\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n",
            "Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n",
            "Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n",
            "Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n",
            "Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n",
            "Dl Size...:  83% 5/6 [00:05<00:05,  5.02s/ MiB]\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n",
            "Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n",
            "Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n",
            "Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n",
            "Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n",
            "Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n",
            "Dl Size...: 11 MiB [00:05,  1.57 MiB/s]\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n",
            "Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n",
            "Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n",
            "Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n",
            "Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n",
            "Dl Size...: 16 MiB [00:05,  3.75 MiB/s]\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n",
            "Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n",
            "Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n",
            "Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n",
            "Dl Completed...:   0% 0/1 [00:05<?, ? url/s]\n",
            "Dl Completed...: 100% 1/1 [00:05<00:00,  5.49s/ url]\n",
            "Dl Size...: 21 MiB [00:05,  3.83 MiB/s]\n",
            "Dl Completed...: 100% 1/1 [00:05<00:00,  5.49s/ url]\n",
            "Generating splits...:   0% 0/2 [00:00<?, ? splits/s]\n",
            "Generating train examples...: 0 examples [00:00, ? examples/s]\u001b[A\n",
            "Generating train examples...: 687 examples [00:00, 6861.19 examples/s]\u001b[A\n",
            "Generating train examples...: 1374 examples [00:00, 6728.81 examples/s]\u001b[A\n",
            "Generating train examples...: 2048 examples [00:00, 6168.98 examples/s]\u001b[A\n",
            "Generating train examples...: 2670 examples [00:00, 5983.13 examples/s]\u001b[A\n",
            "Generating train examples...: 3361 examples [00:00, 6294.62 examples/s]\u001b[A\n",
            "Generating train examples...: 3995 examples [00:00, 5163.24 examples/s]\u001b[A\n",
            "Generating train examples...: 4545 examples [00:00, 5254.79 examples/s]\u001b[A\n",
            "Generating train examples...: 5093 examples [00:00, 5249.98 examples/s]\u001b[A\n",
            "Generating train examples...: 5739 examples [00:01, 5593.37 examples/s]\u001b[A\n",
            "Generating train examples...: 6454 examples [00:01, 6043.57 examples/s]\u001b[A\n",
            "Generating train examples...: 7071 examples [00:01, 5910.04 examples/s]\u001b[A\n",
            "Generating train examples...: 7671 examples [00:01, 5867.18 examples/s]\u001b[A\n",
            "Generating train examples...: 8264 examples [00:01, 5288.66 examples/s]\u001b[A\n",
            "Generating train examples...: 8807 examples [00:01, 4942.86 examples/s]\u001b[A\n",
            "Generating train examples...: 9418 examples [00:01, 5251.20 examples/s]\u001b[A\n",
            "Generating train examples...: 10654 examples [00:01, 7198.57 examples/s]\u001b[A\n",
            "Generating train examples...: 11884 examples [00:01, 8633.41 examples/s]\u001b[A\n",
            "Generating train examples...: 13148 examples [00:01, 9780.64 examples/s]\u001b[A\n",
            "Generating train examples...: 14327 examples [00:02, 10364.16 examples/s]\u001b[A\n",
            "Generating train examples...: 15538 examples [00:02, 10875.55 examples/s]\u001b[A\n",
            "Generating train examples...: 16789 examples [00:02, 11356.60 examples/s]\u001b[A\n",
            "Generating train examples...: 17952 examples [00:02, 11437.56 examples/s]\u001b[A\n",
            "Generating train examples...: 19104 examples [00:02, 11349.11 examples/s]\u001b[A\n",
            "Generating train examples...: 20364 examples [00:02, 11718.34 examples/s]\u001b[A\n",
            "Generating train examples...: 21557 examples [00:02, 11780.07 examples/s]\u001b[A\n",
            "Generating train examples...: 22778 examples [00:02, 11907.06 examples/s]\u001b[A\n",
            "Generating train examples...: 24033 examples [00:02, 12093.66 examples/s]\u001b[A\n",
            "Generating train examples...: 25301 examples [00:02, 12266.03 examples/s]\u001b[A\n",
            "Generating train examples...: 26529 examples [00:03, 12191.37 examples/s]\u001b[A\n",
            "Generating train examples...: 27750 examples [00:03, 12059.14 examples/s]\u001b[A\n",
            "Generating train examples...: 28994 examples [00:03, 12170.94 examples/s]\u001b[A\n",
            "Generating train examples...: 30212 examples [00:03, 12055.54 examples/s]\u001b[A\n",
            "Generating train examples...: 31419 examples [00:03, 11623.88 examples/s]\u001b[A\n",
            "Generating train examples...: 32672 examples [00:03, 11884.15 examples/s]\u001b[A\n",
            "Generating train examples...: 33864 examples [00:03, 11817.47 examples/s]\u001b[A\n",
            "Generating train examples...: 35087 examples [00:03, 11937.67 examples/s]\u001b[A\n",
            "Generating train examples...: 36347 examples [00:03, 12129.90 examples/s]\u001b[A\n",
            "Generating train examples...: 37562 examples [00:04, 12021.24 examples/s]\u001b[A\n",
            "Generating train examples...: 38829 examples [00:04, 12210.39 examples/s]\u001b[A\n",
            "Generating train examples...: 40052 examples [00:04, 12076.94 examples/s]\u001b[A\n",
            "Generating train examples...: 41261 examples [00:04, 12039.29 examples/s]\u001b[A\n",
            "Generating train examples...: 42466 examples [00:04, 12042.02 examples/s]\u001b[A\n",
            "Generating train examples...: 43671 examples [00:04, 11617.40 examples/s]\u001b[A\n",
            "Generating train examples...: 44855 examples [00:04, 11681.29 examples/s]\u001b[A\n",
            "Generating train examples...: 46104 examples [00:04, 11917.02 examples/s]\u001b[A\n",
            "                                                                         \u001b[A\n",
            "Shuffling /root/tensorflow_datasets/alpaca/1.0.0.incomplete6AHGOY/alpaca-train.tfrecord*...:   0% 0/46801 [00:00<?, ? examples/s]\u001b[A\n",
            "Shuffling /root/tensorflow_datasets/alpaca/1.0.0.incomplete6AHGOY/alpaca-train.tfrecord*...:  82% 38365/46801 [00:00<00:00, 383621.10 examples/s]\u001b[A\n",
            "INFO[writer.py]: Done writing /root/tensorflow_datasets/alpaca/1.0.0.incomplete6AHGOY/alpaca-train.tfrecord*. Number of examples: 46801 (shards: [46801])\n",
            "Generating splits...:  50% 1/2 [00:04<00:04,  4.94s/ splits]\n",
            "Generating val examples...: 0 examples [00:00, ? examples/s]\u001b[A\n",
            "Generating val examples...: 1288 examples [00:00, 12877.37 examples/s]\u001b[A\n",
            "Generating val examples...: 2619 examples [00:00, 13130.08 examples/s]\u001b[A\n",
            "Generating val examples...: 3933 examples [00:00, 12542.73 examples/s]\u001b[A\n",
            "                                                                      \u001b[A\n",
            "Shuffling /root/tensorflow_datasets/alpaca/1.0.0.incomplete6AHGOY/alpaca-val.tfrecord*...:   0% 0/5201 [00:00<?, ? examples/s]\u001b[A\n",
            "INFO[writer.py]: Done writing /root/tensorflow_datasets/alpaca/1.0.0.incomplete6AHGOY/alpaca-val.tfrecord*. Number of examples: 5201 (shards: [5201])\n",
            "\u001b[1mDataset alpaca downloaded and prepared to /root/tensorflow_datasets/alpaca/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n",
            "INFO[build.py]: Dataset generation complete...\n",
            "\n",
            "tfds.core.DatasetInfo(\n",
            "    name='alpaca',\n",
            "    full_name='alpaca/1.0.0',\n",
            "    description=\"\"\"\n",
            "    TODO(alpaca): Markdown description of that will appear on the catalog page.\n",
            "    Description is **formatted** as markdown.\n",
            "    \n",
            "    It should also contain any processing which has been applied (if any),\n",
            "    (e.g. corrupted example skipped, images cropped,...):\n",
            "    \"\"\",\n",
            "    homepage='https://dataset-homepage/',\n",
            "    data_path='/root/tensorflow_datasets/alpaca/1.0.0',\n",
            "    file_format=tfrecord,\n",
            "    download_size=21.72 MiB,\n",
            "    dataset_size=20.37 MiB,\n",
            "    features=FeaturesDict({\n",
            "        'input': Text(shape=(), dtype=string),\n",
            "        'instruction': Text(shape=(), dtype=string),\n",
            "        'output': Text(shape=(), dtype=string),\n",
            "    }),\n",
            "    supervised_keys=('instruction', 'output'),\n",
            "    disable_shuffling=False,\n",
            "    splits={\n",
            "        'train': <SplitInfo num_examples=46801, num_shards=1>,\n",
            "        'val': <SplitInfo num_examples=5201, num_shards=1>,\n",
            "    },\n",
            "    citation=\"\"\"// TODO(alpaca): BibTeX citation\"\"\",\n",
            ")\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%cd alpaca\n",
        "!tfds build --register_checksums"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SV2qY-qnQZu9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras_nlp\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import alpaca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iYTtNj1vQasq"
      },
      "outputs": [],
      "source": [
        "alpaca_ds = tfds.load('alpaca')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KnYqa20RqUK",
        "outputId": "b83c1813-86e2-446b-d0f9-d663afd8cdde"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec={'input': TensorSpec(shape=(), dtype=tf.string, name=None), 'instruction': TensorSpec(shape=(), dtype=tf.string, name=None), 'output': TensorSpec(shape=(), dtype=tf.string, name=None)}>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "alpaca_ds['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcUzctZ9Q87f",
        "outputId": "c30c84f6-127f-4e6e-a3af-f5b0c8c98df4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'Outline the key components of a business plan.', shape=(), dtype=string)\n",
            "tf.Tensor(b'', shape=(), dtype=string)\n",
            "tf.Tensor(b'The key components of a business plan include an executive summary, a description of the business, marketing information, financial projections, and an evaluation of risks and opportunities.', shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "for x in alpaca_ds['train']:\n",
        "  print(x['instruction'])\n",
        "  print(x['input'])\n",
        "  print(x['output'])\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hQwlLoSFRGho"
      },
      "outputs": [],
      "source": [
        "def get_prompt(x):\n",
        "  def get_prompt_with_input():\n",
        "    result = tf.strings.join([\"### Instruction:\\n\", x['instruction']])\n",
        "    result = tf.strings.join([result, '\\n\\n'])\n",
        "\n",
        "    result = tf.strings.join([result, \"### Input:\\n\"])\n",
        "    result = tf.strings.join([result, x['input']])\n",
        "    result = tf.strings.join([result, '\\n\\n'])\n",
        "\n",
        "    result = tf.strings.join([result, \"### Response:\\n\"])\n",
        "    result = tf.strings.join([result, x['output']])\n",
        "    return result\n",
        "\n",
        "  def get_prompt_without_input():\n",
        "    result = tf.strings.join([\"### Instruction:\\n\", x['instruction']])\n",
        "    result = tf.strings.join([result, '\\n\\n'])\n",
        "\n",
        "    result = tf.strings.join([result, \"### Response:\\n\"])\n",
        "    result = tf.strings.join([result, x['output']])\n",
        "    return result\n",
        "\n",
        "  result = tf.cond(\n",
        "      tf.math.equal(x['input'], ''),\n",
        "      get_prompt_with_input,\n",
        "      get_prompt_without_input\n",
        "  )\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hHJFrIDKT6s5"
      },
      "outputs": [],
      "source": [
        "train_ds = (\n",
        "    alpaca_ds['train'].map(lambda x: get_prompt(x))\n",
        "    .batch(32)\n",
        "    .cache()\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lr4qf--2T66p",
        "outputId": "8ef368ec-3cce-4036-d0fe-e746c24acc98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[b'### Instruction:\\nOutline the key components of a business plan.\\n\\n### Input:\\n\\n\\n### Response:\\nThe key components of a business plan include an executive summary, a description of the business, marketing information, financial projections, and an evaluation of risks and opportunities.'\n",
            " b'### Instruction:\\nWrite about the benefits of cloud computing.\\n\\n### Input:\\n\\n\\n### Response:\\nCloud computing offers a number of advantages that make it an attractive solution for businesses of all sizes. It provides cost savings due to the low infrastructure investment needed to develop or access a cloud-based service, scalability due to the ability to quickly and easily adjust resources to meet current and changing needs, and faster application development, as cloud-based applications can be built and deployed quickly with minimal setup. Additionally, cloud computing can provide a better user experience, as users can access their data and applications from any device and location, and greater security, as data can be stored and backed up in multiple locations.'\n",
            " b'### Instruction:\\nRewrite this sentence into a passive voice: \\xe2\\x80\\x9cJohn built the wall.\\n\\n### Input:\\n\\n\\n### Response:\\nThe wall was built by John.'\n",
            " b'### Instruction:\\nFind the two numbers in the text below and return the sum.\\n\\n### Response:\\nSum: 16'\n",
            " b'### Instruction:\\nDefine the term \"assembly language\".\\n\\n### Input:\\n\\n\\n### Response:\\nAssembly language is a low-level programming language that is made up of mnemonics and it represents a specific processor instruction in symbolic form. It is typically used for writing device drivers, embedded software, and low-level programs for game consoles and operating systems.'\n",
            " b'### Instruction:\\nFill in the blanks to complete the sentence.\\n\\n### Response:\\nGlobal warming can be reversed by reducing greenhouse gas emissions and deforestation.'\n",
            " b'### Instruction:\\nWrite a story about a man\\xe2\\x80\\x99s high-stakes fight\\n\\n### Input:\\n\\n\\n### Response:\\nPeter was an underdog boxer, who had gone through a string of losses in the ring. But after months of training, he finally felt strong and ready to prove himself. With the courage of a fighter, he stepped into the ring one evening and prepared to face his opponent.\\n\\nThe fight was intense, with both men trading punches and neither backing down. Peter fought bravely, and gave it everything he had. After a gruelling 10 rounds, Peter finally emerged victorious. He felt a surge of joy, knowing that his hard work had paid off.\\n\\nFrom then on, Peter was known as a brave and skilled boxer. He was lauded for his determination and grit, and he was rewarded with a much-deserved victory.'\n",
            " b\"### Instruction:\\nExplain the following scientific concept in layperson's terms: chi-squared test\\n\\n### Input:\\n\\n\\n### Response:\\nA chi-squared test is a type of statistical test used to measure the differences between observed and expected outcomes. To do this, the test evaluates how likely it is that the observed data deviate from the expected data. The test's results are based on the chi-squared statistic, which uses a comparison of observed and expected frequencies in a data set. Generally, if the chi-squared value is large, it indicates that there is a significant difference between observed and expected results and vice versa. In simpler terms, a chi-squared test is used to measure the probability that two data sets are related.\"\n",
            " b'### Instruction:\\nGiven a list of integers, show the sum of all the integers.\\n\\n### Response:\\n10'\n",
            " b\"### Instruction:\\nWrite a Wikipedia summary of the University of California, San Francisco in less than 100 words.\\n\\n### Input:\\n\\n\\n### Response:\\nThe University of California, San Francisco (UCSF) is a public research university located in San Francisco, California. Founded in 1864, it is the second-oldest of the ten campuses associated with the University of California system. UCSF enrolls approximately 3,000 undergraduate and 5,000 graduate students every year. The university specializes in the health sciences and is best known for its graduate programs and research in areas such as medicine, dentistry, pharmacology and nursing. Its research teams, which conduct basic and clinical research, are at the forefront of biomedical discoveries, treatments and cures. UCSF's faculty and alumni have earned Nobel Prizes and many other awards for their research and discoveries.\"\n",
            " b'### Instruction:\\nChoose the correct word to complete the sentence:\\n\\nMany species of birds _________ in the winter.\\n\\n### Input:\\n\\n\\n### Response:\\nmigrate'\n",
            " b'### Instruction:\\nIdentify the elements of a crime\\n\\n### Input:\\n\\n\\n### Response:\\nThe elements of a crime are its essential components, which must all be established to prove the criminal act took place. The elements of a crime will vary according to the jurisdiction but generally include the following: actus reus (the guilty act or crime itself), mens rea (the state of mind required to prove the crime such as intent, knowledge, recklessness, or negligence), causation (the link between the criminal act and the resulting harm), harm (the consequence of the criminal act), and guilt (the individual\\xe2\\x80\\x99s culpability for the crime).'\n",
            " b'### Instruction:\\nWhat are the advantages of writing in the first person?\\n\\n### Input:\\n\\n\\n### Response:\\nWriting in the first person has several advantages. It makes the writing more personal and engaging, as the reader is able to directly relate to the narrative. It can also be more effective in conveying certain types of emotions, such as humor or enthusiasm. Additionally, it can help the writer form a stronger bond with the reader, providing them with a stronger incite into their feelings and motivations.'\n",
            " b'### Instruction:\\nWhat topics should a beginner in Data Science learn?\\n\\n### Input:\\n\\n\\n### Response:\\nA beginner in Data Science should learn the basics of Python programming, data wrangling and cleaning, data visualization, basic machine learning algorithms, and statistical analysis.'\n",
            " b'### Instruction:\\nTell me a historically significant event that occured in the year 1948.\\n\\n### Input:\\n\\n\\n### Response:\\nIn 1948, the Arab\\xe2\\x80\\x93Israeli war broke out, resulting in the establishment of the State of Israel.'\n",
            " b'### Instruction:\\nWrite the next sentence in this article.\\n\\n### Response:\\nThe route to the summit is extremely challenging, with steep slopes and variable conditions making it a technical climb, requiring a lot of skills and preparation.'\n",
            " b\"### Instruction:\\nGive five pieces of advice on making friends.\\n\\n### Input:\\n\\n\\n### Response:\\n1. Be yourself \\xe2\\x80\\x93 Be honest, authentic, and open about who you are.\\n2. Don't be afraid to take initiative \\xe2\\x80\\x93 Don't wait to be invited, reach out to people you like first.\\n3. Listen \\xe2\\x80\\x93 Show people that you are interested in getting to know them by listening to them and genuinely engaging in conversation.\\n4. Show kindness \\xe2\\x80\\x93 Being kind and making an effort for others is a great way to make friends.\\n5. Be interested \\xe2\\x80\\x93 Genuinely show interest in what your friends do and care about. Showing genuine interest will make them feel appreciated.\"\n",
            " b\"### Instruction:\\nGive an example of a way to build trust in a professional relationship.\\n\\n### Input:\\n\\n\\n### Response:\\nAn example of how to build trust in a professional relationship is by keeping promises and taking responsibility for one's words and actions. Additionally, allowing the other person to be involved in the decision-making process and being willing to listen to their point of view are important elements of trust building. Being clear and forthright with communication and avoiding insincere compliments or flattery could also help to build trust.\"\n",
            " b\"### Instruction:\\nWrite a tip to make cooking easier.\\n\\n### Input:\\n\\n\\n### Response:\\nOne tip to make cooking easier is to develop a meal plan for the week and make sure to stick to it. This means having ingredients ready to go and prepping any elements of the dish that can be done in advance. That way, when it comes time for the actual meal preparation, a lot of the work is already done, so it's easy to quickly assemble the dish.\"\n",
            " b\"### Instruction:\\nConstruct a poem about the beauty of the night sky with 8 lines and a rhyme scheme of AABB.\\n\\n### Input:\\n\\n\\n### Response:\\nAs I look up to the night sky so high,\\nI see a million stars that twinkle and shine;\\nTheir beauty mesmerizes me, I won't lie,\\nAnd I feel deeply in love with this divine.\\n\\nA blanket of stars in a dark, velvety sky,\\nA ceaseless miracle, an eternity so high;\\nA glimpse of beauty I may never understand why,\\nBut I've been enamored since I caught its bright eyes.\"\n",
            " b'### Instruction:\\nSort the following words by the first letter of their spelling in the English alphabet.\\n\\n### Response:\\nXanthum, Wolf, Yahoo, Zebra'\n",
            " b'### Instruction:\\nGenerate a 5-word metaphor for loneliness.\\n\\n### Input:\\n\\n\\n### Response:\\nLoneliness is an unending ocean of emptiness.'\n",
            " b'### Instruction:\\nDescribe the phenomenon of carbon dioxide absorption in the atmosphere.\\n\\n### Input:\\n\\n\\n### Response:\\nCarbon dioxide is absorbed by plants and sea creatures and is an important component of the carbon cycle in the atmosphere. Through photosynthesis, plants absorb carbon dioxide in order to convert it into food while ocean creatures do the same in order to produce energy. This process helps in balancing the greenhouse effect by preventing the over-accumulation of carbon dioxide into the atmosphere. Carbon dioxide absorption also helps to maintain the balance of oxygen and carbon dioxide levels, which helps in the regulation of Earth\\xe2\\x80\\x99s climate.'\n",
            " b'### Instruction:\\nDescribe the senses experienced when eating your favorite food.\\n\\n### Input:\\n\\n\\n### Response:\\nWhen I eat my favorite food, I can smell the delicious aromas and see the vibrant colors. I can taste the sweet and savory flavors, and feel the different textures of the food. I can also hear the sizzling and crackling of the food in the pan.'\n",
            " b'### Instruction:\\nWrite a short story where a character goes through a transformation\\n\\n### Input:\\n\\n\\n### Response:\\nOnce upon a time, there was a young woman named Sarah who had it all. She had a successful career, wealthy friends, and a status that most aspired to. However, deep down Sarah was unfulfilled. She had a sense of emptiness that nothing seemed to quell. \\n\\nOne day, while out shopping, Sarah stumbled upon an old bookshop. Despite her reservation, she entered and was immediately taken by the musty aroma of ancient scrolls and leather-bound books. She began to browse, marveling at the sheer volume of knowledge contained within the walls of the shop. It was then, while engrossed in her exploration, that she discovered a book that changed her life. \\n\\nThe book contained an ancient scripture exhorting the reader to take control of their life. Sarah began to read, and as her eyes trailed along the writing she felt something stir within her. She began to question her life choices, her values, and her vision of the world. This led her to take a journey of self-discovery and inner transformation.\\n\\nSarah sacrificed the comforts she was accustomed to and began to build a life for herself that was true to her core. She discovered a set of values and beliefs which inspired her and led her to a life of service, compassion, and peace. Sarah had undergone a transformational experience of self-discovery and was determined to live a life that was truly aligned to her highest purpose. \\n\\nAnd so, with fingers burning with the passion of the journey, Sarah transformed and has never looked back since.'\n",
            " b'### Instruction:\\nRecommend 2 books related to the given category that have been released in the past year.\\n\\n### Response:\\n1. The Future is Blue by Catherynne M. Valente \\n2. Intellect by Emily Suvada'\n",
            " b'### Instruction:\\nGiven a sentence, change the tense of the sentence.\\n\\n### Response:\\nShe had watched the movie.'\n",
            " b'### Instruction:\\nWrite a script for a 5-second advertisement describing the company.\\n\\n### Input:\\n\\n\\n### Response:\\nIntroducing XYZ, the one-stop shop for all your needs. Our prices are unbeatable and our quality is top-notch. From home appliances to car parts, XYZ has you covered. Shop with us and make your life easier today!'\n",
            " b'### Instruction:\\nThink of a creative way to say \"I don\\'t know\".\\n\\n### Input:\\n\\n\\n### Response:\\nMy mind is a blank slate.'\n",
            " b\"### Instruction:\\nHow could the given product be improved?\\n\\n### Response:\\nThe product could be improved by updating the operating system to a more modern version, with more features and improved security. Additionally, adding new hardware components such as a faster processor, more RAM, and a larger storage capacity could improve the product's performance and capabilities.\"\n",
            " b'### Instruction:\\nWhy does the sky look blue on a sunny day?\\n\\n### Input:\\n\\n\\n### Response:\\nThe sky looks blue on a sunny day because of a phenomenon called Rayleigh scattering. This occurs when sunlight is scattered off of the Earth\\xe2\\x80\\x99s atmosphere, resulting in short blue wavelengths being scattered more than the longer red, yellow, and orange ones. This causes the sky to appear blue, and as the sun moves across the sky the blue is well lit, providing a bright blue sky.'\n",
            " b'### Instruction:\\nIdentify a target audience for a documentary\\n\\n### Response:\\nA potential target audience for a documentary on human trafficking could be school-aged children. As they are more likely to be unaware of the issue and its risks, they are highly vulnerable to become victims or even perpetrators of trafficking. Additionally, this documentary could be used as an educational tool in classrooms to increase awareness and understanding of the issue. It could also be used to plant seeds of empathy and understanding in students.']\n"
          ]
        }
      ],
      "source": [
        "for data in train_ds.take(1):\n",
        "  print(data.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_tokenizer = keras_nlp.models.GPT2Tokenizer.from_preset(\"gpt2_base_en\")\n",
        "gpt2_preprocessor = keras_nlp.models.GPT2CausalLMPreprocessor.from_preset(\n",
        "    \"gpt2_base_en\",\n",
        "    sequence_length=256,\n",
        "    add_end_token=True,\n",
        ")\n",
        "gpt2_lm = keras_nlp.models.GPT2CausalLM.from_preset(\"gpt2_base_en\", preprocessor=gpt2_preprocessor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrL2UioWUxj8",
        "outputId": "cba0f0e0-d973-4f59-8fc5-af1217947442"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-nlp/models/gpt2_base_en/v1/vocab.json\n",
            "1042301/1042301 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/keras-nlp/models/gpt2_base_en/v1/merges.txt\n",
            "456318/456318 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/keras-nlp/models/gpt2_base_en/v1/model.h5\n",
            "497986112/497986112 [==============================] - 2s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.linalg.matmul), but are not present in its tracked objects:   <tf.Variable 'token_embedding/embeddings:0' shape=(50257, 768) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "atyATI3dUNy_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7951eed-cc00-4b79-9753-ad18fc2c9058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500/500 [==============================] - 977s 2s/step - loss: 0.6793 - accuracy: 0.5528\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7099f91840>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "train_ds = train_ds.take(500)\n",
        "num_epochs = 1\n",
        "\n",
        "# Linearly decaying learning rate.\n",
        "learning_rate = tf.keras.optimizers.schedules.PolynomialDecay(\n",
        "    5e-5,\n",
        "    decay_steps=train_ds.cardinality() * num_epochs,\n",
        "    end_learning_rate=0.0,\n",
        ")\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "gpt2_lm.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
        "    loss=loss,\n",
        "    weighted_metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "gpt2_lm.fit(train_ds, epochs=num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = gpt2_lm.generate(\"### Instruction:\\nWrite a resignation email\", max_length=256)"
      ],
      "metadata": {
        "id": "q-teY-DnVDbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown, Latex\n",
        "display(Markdown(result.split(\"### Response:\")[-1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "aPdjY04CaX6r",
        "outputId": "b3695472-b2b9-4816-d960-a392db656083"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\nDear CEO,\n\nI'm leaving my position today. As you have stated on many occasions, I believe that my decision to terminate an employee was a mistake and I regret it. I apologize for the pain I caused, but I'm determined to make the right decision for my family.\n\nI have been deeply hurt by the decision, and I'm looking forward to working with you to make sure that this decision is not repeated. I look forward to continuing to work with you, and I look forward to meeting you in your office.\n\nSincerely,\n[Your Name]\n\nYour Name"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ik79ml24b-dq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyME4rRSD7cfdB71/29C+4n9"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}